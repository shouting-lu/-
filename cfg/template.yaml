AVA:
  ANNOTATION_DIR: /usr/home/sut/datasets/AVA/annotations/
  BGR: False
  DETECTION_SCORE_THRESH: 0.8
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: /usr/home/sut/datasets/AVA/frames/
  FRAME_LIST_DIR: /usr/home/sut/datasets/AVA/frame_lists/
  FULL_TEST_ON_VAL: False
  GROUNDTRUTH_FILE: ava_val_v2.2.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: ava_action_list_v2.2_for_activitynet_2019.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['val.csv']
  TEST_PREDICT_BOX_LISTS: ['person_box_67091280_iou90/ava_detection_val_boxes_and_labels.csv']
  TRAIN_EXCLUSION_FILE: ava_train_excluded_timestamps_v2.2.csv
  TRAIN_GT_BOX_LISTS: ['ava_train_v2.2.csv']
  TRAIN_LISTS: ['train.csv']
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
  VAL_GT_BOX_LISTS: ['ava_val_v2.2.csv']
BACKUP_DIR: backup/ava
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  EPSILON: 1e-05
  MOMENTUM: 0.1
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
DATA:
  CROP_SIZE: 224
  DEBUG: True
  DECODING_BACKEND: pyav
  ENSEMBLE_METHOD: sum
  INPUT_CHANNEL_NUM: [3, 3]
  INV_UNIFORM_SAMPLE: False
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 32
  PATH_PREFIX: 
  PATH_TO_DATA_DIR: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 1
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 640
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_SCALES: [256, 320]
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 8
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: jf.mp4
  LABEL_FILE_PATH: cfg/action_list_v2.pbtxt
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: ava_jf.mp4
  OUTPUT_FPS: -1
  OUT_PATH: inference/videos
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: False
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
LISTDATA:
  BASE_PTH: /usr/home/sut/datasets/ucf24
  CLASS_NAMES: ['Basketball', 'BasketballDunk', 'Biking', 'CliffDiving', 'CricketBowling', 'Diving', 'Fencing', 'FloorGymnastics', 'GolfSwing', 'HorseRiding', 'IceDancing', 'LongJump', 'PoleVault', 'RopeClimbing', 'SalsaSpin', 'SkateBoarding', 'Skiing', 'Skijet', 'SoccerJuggling', 'Surfing', 'TennisSwing', 'TrampolineJumping', 'VolleyballSpiking', 'WalkingWithDog']
  MAX_OBJS: 6
  TEST_FILE: /usr/home/sut/datasets/ucf24/testlist.txt
  TEST_VIDEO_FILE: /usr/home/sut/datasets/ucf24/testlist_video.txt
  TRAIN_FILE: /usr/home/sut/datasets/ucf24/trainlist.txt
LOG_MODEL_INFO: True
LOG_PERIOD: 10
MODEL:
  ARCH: slowfast
  BACKBONE_2D: darknet
  BACKBONE_3D: resnext101
  DROPOUT_RATE: 0.5
  FC_INIT_STD: 0.01
  HEAD_ACT: softmax
  LOSS_FUNC: cross_entropy
  MODEL_NAME: SlowFast
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 80
  SINGLE_PATHWAY_ARCH: ['c2d', 'i3d', 'slow']
NONLOCAL:
  GROUP: [[1], [1], [1], [1]]
  INSTANTIATION: dot_product
  LOCATION: [[[]], [[]], [[]], [[]]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 1
NUM_SHARDS: 1
OUTPUT_DIR: ./tmp
RESNET:
  DEPTH: 50
  DISSECTED: False
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1], [1], [1], [1]]
  SPATIAL_STRIDES: [[1], [2], [2], [2]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: False
RNG_SEED: 1
SHARD_ID: 0
SLOWFAST:
  ALPHA: 8
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  ANCHORS: [0.71626, 2.13583, 1.28967, 4.15014, 2.12714, 5.09344, 3.27212, 5.87423, 5.16303, 6.33821]
  BASE_LR: 0.1
  CLASS_SCALE: 1
  COORD_SCALE: 1
  DAMPENING: 0.0
  GAMMA: 0.1
  LRS: []
  LR_DECAY_RATE: 0.5
  LR_POLICY: cosine
  MAX_EPOCH: 300
  MOMENTUM: 0.9
  NESTEROV: True
  NOOBJECT_SCALE: 1
  NUM_ANCHORS: 5
  OBJECT_SCALE: 5
  OPTIMIZING_METHOD: sgd
  STEPS: [3, 4, 5, 6]
  STEP_SIZE: 1
  WARMUP_EPOCHS: 0.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 0.01
  WEIGHT_DECAY: 0.0001
TEST:
  BATCH_SIZE: 8
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_TYPE: pytorch
  DATASET: kinetics
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 10
  NUM_SPATIAL_CROPS: 3
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 6
  BEGIN_EPOCH: 1
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_INFLATE: False
  CHECKPOINT_PERIOD: 1
  CHECKPOINT_TYPE: pytorch
  CLASS_RATIO_FILE: cfg/ava_categories_ratio.json
  DATASET: ava
  DETECT_PATH: 
  ENABLE: True
  END_EPOCH: 10
  EVALUATE: True
  EVAL_PERIOD: 1
  FINE_TUNE: False
  LEARNING_RATE: 0.0001
  MODE: val
  ONLY_DETECT: False
  RESUME_PATH: pretrained/yowo_ava_16f_s2_best_ap_01719.pth
  TOTAL_BATCH_SIZE: 128
  USE_GROUNDTRUTH: False
  USE_SLOWFAST: False
WEIGHTS:
  BACKBONE_2D: 
  BACKBONE_3D: 
  FREEZE_BACKBONE_2D: False
  FREEZE_BACKBONE_3D: False